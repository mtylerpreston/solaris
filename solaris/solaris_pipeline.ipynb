{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tyler/anaconda3/envs/solaris/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Tyler/anaconda3/envs/solaris/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Tyler/anaconda3/envs/solaris/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Tyler/anaconda3/envs/solaris/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Tyler/anaconda3/envs/solaris/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Tyler/anaconda3/envs/solaris/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy.distance\n",
    "import json\n",
    "import shapely.geometry\n",
    "import sys\n",
    "import os\n",
    "import solaris as sol\n",
    "from solaris.data import data_dir\n",
    "import os\n",
    "import skimage\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.ops import cascaded_union\n",
    "from os.path import expanduser\n",
    "\n",
    "# we need to make sure the reportlib directory is on sys.path\n",
    "sys.path.append(os.path.join(expanduser(\"~\"), \"reportlib\")) \n",
    "import dbpersonalization as per\n",
    "import dbhelpers as hlps\n",
    "\n",
    "# CONST\n",
    "LEFT = \"https://s3-us-west-2.amazonaws.com/prod-betterview\" # in case we want to make image url\n",
    "\n",
    "# conn\n",
    "rrep = hlps.dbconn(per.reportUser, per.reportPass)\n",
    "tabs = hlps.dbconn(per.mssqlUser, per.mssqlPass, host=per.mssqlHost \\\n",
    "                   , database=per.mssqlData, driver=per.mssqlDriv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>footprint_data</th>\n",
       "      <th>bounding_box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>130628</td>\n",
       "      <td>https://s3-us-west-2.amazonaws.com/prod-better...</td>\n",
       "      <td>{\"buildings\": [[[{\"lat\": 32.353316, \"lng\": -90...</td>\n",
       "      <td>(32.353586,-90.176684),(32.353296,-90.176878)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    property_id                                            img_url  \\\n",
       "35       130628  https://s3-us-west-2.amazonaws.com/prod-better...   \n",
       "\n",
       "                                       footprint_data  \\\n",
       "35  {\"buildings\": [[[{\"lat\": 32.353316, \"lng\": -90...   \n",
       "\n",
       "                                     bounding_box  \n",
       "35  (32.353586,-90.176684),(32.353296,-90.176878)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set of properties\n",
    "df = pd.read_excel('data/test_properties.xlsx')\n",
    "footprint = json.loads(df.footprint_data.iloc[101])\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set of properties with Tyler groundtruth on material\n",
    "rrep.plugin()\n",
    "new_df = pd.read_sql('''select distinct on (property_id) property_id, img_url, tile_bounding_box, footprint_data\n",
    "                    from pibd_consolidation\n",
    "                    where property_id in (224875, 215045, 194289, 199665, 244494, 234129, 233401, 233350, 243390, 213324, 199747, 234490, 234638, 234934, 244377, 244547, 213914, 199574, 242951, 212851, 215052, 244044, 244051, 244291, 208483, 199465, 244211, 243474, 234907, 213901, 208460, 241098, 216077, 216108, 234064, 243574, 225086, 209865, 199786, 233943, 250787, 244073, 233167, 234640, 250972, 244632, 244123, 241872, 218487, 243094, 224904, 234827, 243737, 233962, 216095, 199923, 244661, 250970, 243761, 251198, 208468, 250857, 215014, 233557, 244360, 244433, 216134, 234513, 217303, 224795, 215938, 216219, 212854, 233166, 233387, 225085, 234314, 233180, 233860, 224714, 199620, 194344, 217900, 218008, 234231, 224778, 233715, 209634, 250831, 224936, 242176, 199681, 224728, 216169, 199883, 251039, 209914, 224825, 244688)\n",
    "                    and provider_type_id = 2 and building_count > 0''', \n",
    "                     rrep.conn)\n",
    "rrep.unplug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detail Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_bounding_box(bb):\n",
    "    '''\n",
    "    Take in raw bounding box data from df and split it into \n",
    "    its 4 components (2 coordinates for each of 2 corners)\n",
    "    '''\n",
    "    return [float(coordinate) for coordinate in bb.replace('(','').replace(')','').split(',')]\n",
    "\n",
    "def get_bb_origin_latlong(bb):\n",
    "    '''\n",
    "    Takes bounding box input as list of floats (2 coordinates \n",
    "    for each of 2 corners).\n",
    "    \n",
    "    Outputs lat long as a list that would be the top left corner of the image\n",
    "    '''\n",
    "    # Parse data in bb string (unfortuantely json.loads wasn't working out here)\n",
    "    bb = split_bounding_box(bb)\n",
    "    \n",
    "    # First coordinates are top left\n",
    "    if bb[0]>bb[2] and bb[1]<bb[3]:\n",
    "        return bb[0:2]\n",
    "    # First coordinates are top right\n",
    "    elif bb[0]>bb[2] and bb[1]>bb[3]:\n",
    "        return [bb[0], bb[3]]\n",
    "    # Some other scenario that we don't expect\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def convert_url_to_img(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "def calculate_dist_cm(coords1, coords2):\n",
    "    return geopy.distance.geodesic(coords1, coords2).m*100\n",
    "\n",
    "def calculate_gsd(bb, img):\n",
    "    # Parse data in bb string (unfortuantely json.loads wasn't working out here)\n",
    "    bb = split_bounding_box(bb)\n",
    "    \n",
    "    coords_1 = (bb[0:2])\n",
    "    coords_2 = (bb[2:4])\n",
    "    \n",
    "    dist_cm = calculate_dist_cm(coords_1, coords_2)\n",
    "\n",
    "    dist_p = np.sqrt(img.size[0]**2 + img.size[1]**2)\n",
    "    return dist_cm/dist_p\n",
    "\n",
    "def latlong_to_pixels(bb, footprint, img_url, verbose = False):\n",
    "    '''\n",
    "    bb: bounding_box coordinates in lat long\n",
    "    bv_footprints: building footprint coordinates in lat long\n",
    "    '''\n",
    "    \n",
    "    # Get image from url\n",
    "    img = convert_url_to_img(img_url)\n",
    "    \n",
    "    # Get gsd in cm/pixel for interpreting pixel dimensions\n",
    "    gsd = calculate_gsd(bb, img)\n",
    "    \n",
    "    # Get origin lat long (top left corner of image)\n",
    "    origin = get_bb_origin_latlong(bb)\n",
    "    \n",
    "    if verbose:\n",
    "        print('GSD: {}'.format(gsd))\n",
    "        print('Origin: {}'.format(origin))\n",
    "    # Iterate through coordinates to get distances from origin to each point in footprint\n",
    "    footprint_cp = footprint.copy()\n",
    "    for idx, coordinate in enumerate(footprint):\n",
    "        long_dist = calculate_dist_cm(origin, (origin[0], coordinate['lng']))\n",
    "        lat_dist = calculate_dist_cm(origin, (coordinate['lat'], origin[1]))\n",
    "        \n",
    "        x_pix = int(long_dist/gsd)\n",
    "        y_pix = int(lat_dist/gsd)\n",
    "        if verbose:\n",
    "            print(x_pix, y_pix)\n",
    "            \n",
    "        footprint_cp[idx] = (x_pix, y_pix)\n",
    "    return footprint_cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bvp_to_geojson(bb, building_footprints, img_url):\n",
    "    '''\n",
    "    bb: bounding_box coordinates in lat long\n",
    "    bv_footprints: building footprint coordinates in lat long\n",
    "    \n",
    "    output: geojson file with pixel coordinates instead of lat long\n",
    "    '''\n",
    "    building_footprints = building_footprints['buildings'][0]   \n",
    "    building_footprints_cp = building_footprints.copy()\n",
    "\n",
    "    # Convert each building footprint from lat/long to pixel coords\n",
    "    polygons = []\n",
    "    for idx, footprint in enumerate(building_footprints):\n",
    "        footprint = latlong_to_pixels(bb, footprint, img_url)\n",
    "        \n",
    "#         # Original approach\n",
    "#         polygon = shapely.geometry.Polygon(footprint)\n",
    "#         building_footprints_cp[idx] = gpd.GeoSeries(polygon).__geo_interface__\n",
    "        \n",
    "        # Try getting a list of polygons and converting that to geojson?\n",
    "        polygons.append(shapely.geometry.Polygon(footprint))\n",
    "    geojsons = gpd.GeoSeries(polygons).__geo_interface__\n",
    "        \n",
    "    return geojsons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare BV's geojson mask labels from building footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'FeatureCollection',\n",
       " 'features': [{'id': '0',\n",
       "   'type': 'Feature',\n",
       "   'properties': {},\n",
       "   'geometry': {'type': 'Polygon',\n",
       "    'coordinates': (((131.0, 212.0),\n",
       "      (152.0, 213.0),\n",
       "      (154.0, 171.0),\n",
       "      (132.0, 170.0),\n",
       "      (131.0, 212.0)),)},\n",
       "   'bbox': (131.0, 170.0, 154.0, 213.0)},\n",
       "  {'id': '1',\n",
       "   'type': 'Feature',\n",
       "   'properties': {},\n",
       "   'geometry': {'type': 'Polygon',\n",
       "    'coordinates': (((162.0, 284.0),\n",
       "      (189.0, 284.0),\n",
       "      (189.0, 226.0),\n",
       "      (162.0, 226.0),\n",
       "      (162.0, 284.0)),)},\n",
       "   'bbox': (162.0, 226.0, 189.0, 284.0)}],\n",
       " 'bbox': (131.0, 170.0, 189.0, 284.0)}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of running the process for one property\n",
    "bb = new_df.tile_bounding_box.iloc[5]\n",
    "building_footprints = new_df.footprint_data.iloc[5]\n",
    "url = new_df.img_url.iloc[1]\n",
    "\n",
    "results = bvp_to_geojson(bb, building_footprints, url)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And here we will run that process for all properties in our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['geojsons'] = new_df.apply(lambda x: bvp_to_geojson(x['tile_bounding_box'], x['footprint_data'], x['img_url']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a look at what that gives us for one property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-32e6417637de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbv_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeojsons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/bv_test/bv_test_mask.geojson'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbv_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "bv_mask = new_df.geojsons.iloc[2][0]\n",
    "img_url = new_df.img_url.iloc[2]\n",
    "with open('data/bv_test/bv_test_mask.geojson', 'w') as file:\n",
    "    file.write(json.dumps(bv_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = skimage.io.imread(os.path.join(data_dir, 'sample_geotiff.tif'))\n",
    "# f, axarr = plt.subplots(figsize=(10, 10))\n",
    "# plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('data/bv_test/bv_test_mask.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALkAAAHVCAYAAACt7FrJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARNklEQVR4nO3df6hfd33H8edrjdWhrmk6F0IS1opB8Y9Z48VFJoMpjrYbS/8QUQYNUsg/21AcbBmDwf50f+gsSFlQtxScv6rSMJxbjQX/avVGa1qtNbdukoS0mVqrTpi6vffH/YR+G5t7v/dXvjfv+3zA4XvO55zv/Z5Dn99zz/d8U26qCqmzX5n1DkgbzcjVnpGrPSNXe0au9oxc7W1I5EluSfJ4koUkRzbiNaRpZb3vkye5Bvg28BbgLPAV4B1V9c11fSFpShtxJn89sFBV36mqnwEfBw5uwOtIU9m2AT9zN3BmYvks8NuXbpTkMHB4LL5uA/ZDW8v3quplz7diIyKfSlUdBY4CJPHfFmitvnu5FRtxuXIO2DuxvGeMSTOxEZF/BdiX5KYk1wJvB45vwOtIU1n3y5Wq+kWSPwX+DbgG+EhVfWO9X0ea1rrfQlzVTnhNrrU7WVVzz7fCbzzVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqb9nIk3wkyYUkj06M7Uhyf5LT4/H6MZ4kdyVZSHIqyf6N3HlpGtOcyf8JuOWSsSPAiaraB5wYywC3AvvGdBi4e312U1q9ZSOvqi8BP7hk+CBwbMwfA26fGL+nFj0IbE+ya712VlqN1V6T76yq82P+SWDnmN8NnJnY7uwY+yVJDieZTzK/yn2QprJtrT+gqipJreJ5R4GjAKt5vjSt1Z7Jn7p4GTIeL4zxc8Deie32jDFpZlYb+XHg0Jg/BNw3MX7HuMtyAHhm4rJGmo2qWnICPgacB37O4jX2ncANLN5VOQ18Adgxtg3wQeAJ4BFgbrmfP55XTk5rnOYv11dGZDPlNbnWwcmqmnu+FX7jqfaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rq71lI0+yN8kDSb6Z5BtJ3jXGdyS5P8np8Xj9GE+Su5IsJDmVZP9GH4S0lGnO5L8A/ryqXg0cAP4kyauBI8CJqtoHnBjLALcC+8Z0GLh73fdaWoFlI6+q81X11TH/Y+AxYDdwEDg2NjsG3D7mDwL31KIHge1Jdq37nktTWtE1eZIbgdcCDwE7q+r8WPUksHPM7wbOTDzt7Bi79GcdTjKfZH6F+yytyNSRJ3kJ8Gng3VX1o8l1VVVAreSFq+poVc1V1dxKniet1FSRJ3kBi4F/tKo+M4afungZMh4vjPFzwN6Jp+8ZY9JMTHN3JcCHgceq6n0Tq44Dh8b8IeC+ifE7xl2WA8AzE5c10pVXVUtOwBtZvBQ5BTw8ptuAG1i8q3Ia+AKwY2wf4IPAE8AjwNwUr1FOTmuc5i/XV0ZkM5Vk9juhq93Jy32+8xtPtWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52ls28iQvSvLlJF9P8o0kfzvGb0ryUJKFJJ9Icu0Yf+FYXhjrb9zYQ5CWNs2Z/H+AN1XVa4CbgVuSHADeC7y/ql4BPA3cOba/E3h6jL9/bCfNzLKR16KfjMUXjKmANwH3jvFjwO1j/uBYZqx/c5Ks2x5LKzTVNXmSa5I8DFwA7geeAH5YVb8Ym5wFdo/53cAZgLH+GeCG5/mZh5PMJ5lf2yFIS5sq8qr636q6GdgDvB541VpfuKqOVtVcVc2t9WdJS1nR3ZWq+iHwAPAGYHuSbWPVHuDcmD8H7AUY668Dvr8ueyutwjR3V16WZPuY/1XgLcBjLMb+1rHZIeC+MX98LDPWf7Gqaj13WlqRqlpyAn4L+BpwCngU+Jsx/nLgy8AC8CnghWP8RWN5Yax/+RSvUU5Oa5zmL9dXNsNJNsnsd0JXu5OX+3znN55qz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrva2TOQTf05RW8y25TfpZanQk1zBPdGVsiUin/YM7hugpy0R+XpY7o3im2DzMvJ14m+BzcvIr4DJN4DBX3lGfoV52XPlGfkm42XP+msfead7474BVqd95FvFpW8Ao3+WkTflWf9ZU3+tn+SaJF9L8i9j+aYkDyVZSPKJJNeO8ReO5YWx/saN2XWt1sV/4jA5dbaSf7vyLuCxieX3Au+vqlcATwN3jvE7gafH+PvHdtLMTBV5kj3AHwAfGssB3gTcOzY5Btw+5g+OZcb6N2er/X7UpjLtmfzvgb8A/m8s3wD8sKp+MZbPArvH/G7gDMBY/8zY/jmSHE4yn2R+lfsuTWXZyJP8IXChqk6u5wtX1dGqmququfX8uZe8xkb9aF1Fprm78jvAHyW5DXgR8GvAB4DtSbaNs/Ue4NzY/hywFzibZBtwHfD9dd9zaUrLnsmr6q+qak9V3Qi8HfhiVf0x8ADw1rHZIeC+MX98LDPWf7E8pW5q3T8yreX/DPpL4D1JFli85v7wGP8wcMMYfw9wZG27KK1NNsNJNsmG7MRmOLarQZMz+cnLfb7bMv+Pp7YuI1d7bSP3UkUXtY1cusjIt7gmHzqX1DJyL1U0qWXk0iQjV3tGrvaMXO0Zudoz8i1sK9w+BCPXFtAucu+R61LtIpcuZeRb1Fa5Hgcj1xZg5GrPyNWekau9VpF7+1DPp1Xk0vMx8i1oK90+BCPXFmDkas/I1V6byL2zostpE7l0OUau9oxc7bWI3Ovx6W21e+TQJHJpKUau9oxc7Rm52jNytWfkau+qj9zbh9PbircPoUHkSbbsfzxNZ5o/O35VWCp0z/ZbW5vIl3LpG8Dot5YtEfmltuJZfytf0m3JyJeyFd8A3Rn5Cix3NvRNsDkZ+Try2n9zMvIN5KXP5mDkM+Klz5Uz1ZdBSf4zySNJHk4yP8Z2JLk/yenxeP0YT5K7kiwkOZVk/0YeQFcXv+S6dNLKreQbz9+rqpuram4sHwFOVNU+4MRYBrgV2Demw8Dd67Wz+uX4p33OVraWr/UPAsfG/DHg9onxe2rRg8D2JLvW8DpawuXO+J75nzVt5AX8e5KTSQ6PsZ1VdX7MPwnsHPO7gTMTzz07xp4jyeEk8xcvf7QxDH36D55vrKpzSX4DuD/JtyZXVlUlWdEnpao6ChwFWOlzpZWY6kxeVefG4wXgs8DrgacuXoaMxwtj83PA3omn7xlj0kwsG3mSFyd56cV54PeBR4HjwKGx2SHgvjF/HLhj3GU5ADwzcVkjXXHTXK7sBD47ru22Af9cVZ9P8hXgk0nuBL4LvG1s/zngNmAB+CnwznXfa2kFshm+dPCaXOvg5MTt7ee46v/PIGk5Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekau9qSJPsj3JvUm+leSxJG9IsiPJ/UlOj8frx7ZJcleShSSnkuzf2EOQljbtmfwDwOer6lXAa4DHgCPAiaraB5wYywC3AvvGdBi4e133WFqpqlpyAq4D/gPIJeOPA7vG/C7g8TH/D8A7nm+7JV6jnJzWOM1frq9pzuQ3Af8F/GOSryX5UJIXAzur6vzY5klg55jfDZyZeP7ZMfYcSQ4nmU8yP8U+SKs2TeTbgP3A3VX1WuC/efbSBIBaPB3XSl64qo5W1VxVza3kedJKTRP5WeBsVT00lu9lMfqnkuwCGI8XxvpzwN6J5+8ZY9JMLBt5VT0JnEnyyjH0ZuCbwHHg0Bg7BNw35o8Dd4y7LAeAZyYua6QrbtuU2/0Z8NEk1wLfAd7J4hvkk0nuBL4LvG1s+zngNmAB+OnYVpqZjLsbs92JZPY7oavdyct9vvMbT7Vn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudpbNvIkr0zy8MT0oyTvTrIjyf1JTo/H68f2SXJXkoUkp5Ls3/jDkC5v2cir6vGqurmqbgZeB/wU+CxwBDhRVfuAE2MZ4FZg35gOA3dvxI5L01rp5cqbgSeq6rvAQeDYGD8G3D7mDwL31KIHge1Jdq3L3kqrsNLI3w58bMzvrKrzY/5JYOeY3w2cmXjO2TH2HEkOJ5lPMr/CfZBWZOrIk1wL/BHwqUvXVVUBtZIXrqqjVTVXVXMreZ60Uis5k98KfLWqnhrLT128DBmPF8b4OWDvxPP2jDFpJlYS+Tt49lIF4DhwaMwfAu6bGL9j3GU5ADwzcVkjXXlVtewEvBj4PnDdxNgNLN5VOQ18AdgxxgN8EHgCeASYm+Lnl5PTGqf5y/WVEdlMJZn9Tuhqd/Jyn+/8xlPtGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9oxc7Rm52jNytWfkas/I1Z6Rqz0jV3tGrvaMXO0ZudozcrVn5GrPyNWekas9I1d7Rq72jFztGbnaM3K1Z+Rqz8jVnpGrPSNXe0au9rbNegeGnwCPz3onNtivA9+b9U5ssFke429ebsVmifzx7n8FLsm8xzgbXq6oPSNXe5sl8qOz3oErwGOckU3x19+kjbRZzuTShjFytTfzyJPckuTxJAtJjsx6f1YryUeSXEjy6MTYjiT3Jzk9Hq8f40ly1zjmU0n2z27Pp5Nkb5IHknwzyTeSvGuMb/5jnObPjm/UBFzD4p8nfzlwLfB14NWz3Kc1HMvvAvuBRyfG/g44MuaPAO8d87cB/8rin2g/ADw06/2f4vh2AfvH/EuBbwOvvhqOcdZn8tcDC1X1nar6GfBx4OCM92lVqupLwA8uGT4IHBvzx4DbJ8bvqUUPAtuT7Loye7o6VXW+qr465n8MPAbs5io4xllHvhs4M7F8dox1sbOqzo/5J4GdY/6qPu4kNwKvBR7iKjjGWUe+ZdTi7/Cr/n5tkpcAnwbeXVU/mly3WY9x1pGfA/ZOLO8ZY108dfFX9Hi8MMavyuNO8gIWA/9oVX1mDG/6Y5x15F8B9iW5Kcm1wNuB4zPep/V0HDg05g8B902M3zHuQBwAnpn4lb8pJQnwYeCxqnrfxKrNf4yb4FP7bSx+Un8C+OtZ788ajuNjwHng5yxef94J3ACcAE4DXwB2jG0DfHAc8yPA3Kz3f4rjeyOLlyKngIfHdNvVcIx+ra/2Zn25Im04I1d7Rq72jFztGbnaM3K1Z+Rq7/8Bb1oAQeHldDAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp_mask = sol.vector.mask.footprint_mask(df=os.path.join('data/bv_test/bv_test_mask.geojson'),\n",
    "                                      reference_im=img_url)\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "_ = plt.imshow(fp_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3-us-west-2.amazonaws.com/prod-betterview/masked/static/199574/4cqiOBRWzD.jpeg'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...these seem to match up fairly well (forgiving the data quality issues with finer points of building footprints)\n",
    "\n",
    "\n",
    "# So let's wrap up that up into a function and run it for all properties...\n",
    "\n",
    "### Detail Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(path, filename, geojson):\n",
    "    with open(path + str(filename) + '.geojson', 'w') as file:\n",
    "        file.write(json.dumps(geojson))\n",
    "        \n",
    "def create_geojson_files(df, path):\n",
    "    df.apply(lambda x: save_to_file(path,\n",
    "                                       x['property_id'], x['geojsons']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Level Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks_from_geojson(df, path):\n",
    "    create_geojson_files(df, path)\n",
    "    \n",
    "    # Iterative approach work here\n",
    "    for row in df.iterrows():\n",
    "#         print('This is the row: {}'.format(row[1]))\n",
    "        print()\n",
    "        for footprint in row[1].geojsons:\n",
    "            gdf = gpd.read_file(path + str(row[1].property_id) + '.geojson')\n",
    "            print('This is the gdf: {}'.format(gdf))\n",
    "            break\n",
    "    # Pandas approach here\n",
    "#     gpd_dfs = df.apply(lambda x: gpd.read_file(path + \"/\" + str(x['property_id']) + '.geojson'))\n",
    "#     fp_mask = df.apply( lambda x:\n",
    "#                 sol.vector.mask.footprint_mask(\n",
    "#                     df=os.path.join(\n",
    "#                         path + \"/\" + str(x['property_id']) + '.geojson'), reference_im=img_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "DriverError",
     "evalue": "'/Users/Tyler/betterview/solaris/solaris/data/bv_test/194289.geojson' not recognized as a supported file format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: '/Users/Tyler/betterview/solaris/solaris/data/bv_test/194289.geojson' not recognized as a supported file format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-6bbf7e9550c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/Tyler/betterview/solaris/solaris/data/bv_test/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcreate_masks_from_geojson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-153-1fd5b8c23c4a>\u001b[0m in \u001b[0;36mcreate_masks_from_geojson\u001b[0;34m(df, path)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfootprint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeojsons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperty_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.geojson'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This is the gdf: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, bbox, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0;32m--> 253\u001b[0;31m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: '/Users/Tyler/betterview/solaris/solaris/data/bv_test/194289.geojson' not recognized as a supported file format."
     ]
    }
   ],
   "source": [
    "path = '/Users/Tyler/betterview/solaris/solaris/data/bv_test/'\n",
    "create_masks_from_geojson(new_df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('data/bv_test/243094.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other attempt that stalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cloudinary_urls.csv')\n",
    "df.drop(columns = ['aspect_ratio', 'folder', 'resource_type'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>Material\n",
       "a = asphalt shingle   t = clay tile\n",
       "mb = mod bit           m = metal\n",
       "p = pvc/tpo               e = epdm\n",
       "ra = rolled asphalt    c = roof coating \n",
       "b = ballasted            bur = built-up</th>\n",
       "      <th>Overhang</th>\n",
       "      <th>Damage\n",
       "s = severe\n",
       "m = minor\n",
       "n = none</th>\n",
       "      <th>Ponding</th>\n",
       "      <th>Rust\n",
       "s = severe\n",
       "m = minor\n",
       "n = none</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Construction\n",
       "c = construction</th>\n",
       "      <th>Wear &amp; tear\n",
       "n = none\n",
       "l = likely\n",
       "y = yes</th>\n",
       "      <th>Patching\n",
       "e = extensive\n",
       "m = moderate\n",
       "n = none</th>\n",
       "      <th>VA_ID</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Screen_Shot_2018-10-11_at_11.53.56_AM</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA557</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name  \\\n",
       "555  Screen_Shot_2018-10-11_at_11.53.56_AM   \n",
       "\n",
       "    Material\\na = asphalt shingle   t = clay tile\\nmb = mod bit           m = metal\\np = pvc/tpo               e = epdm\\nra = rolled asphalt    c = roof coating \\nb = ballasted            bur = built-up  \\\n",
       "555                                                  a                                                                                                                                                       \n",
       "\n",
       "     Overhang Damage\\ns = severe\\nm = minor\\nn = none  Ponding  \\\n",
       "555       NaN                                     NaN      NaN   \n",
       "\n",
       "    Rust\\ns = severe\\nm = minor\\nn = none  Shape  \\\n",
       "555                                   NaN    NaN   \n",
       "\n",
       "    Construction\\nc = construction Wear & tear\\nn = none\\nl = likely\\ny = yes  \\\n",
       "555                            NaN                                        NaN   \n",
       "\n",
       "    Patching\\ne = extensive\\nm = moderate\\nn = none  VA_ID comments  \n",
       "555                                             NaN  VA557      NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv('data/labeled_roof_material_zoom.csv')\n",
    "label_df.drop(columns = ['width', 'height', 'megabytes', 'aspect_ratio', 'folder', 'upload_date', 'secure_url', 'image_format', 'resource_type', 'image', 'assignment', 'upload_status', 'status'], inplace = True)\n",
    "label_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the material map for labels\n",
    "material_map = {'a': 'asphalt shingle', \n",
    "                't': 'clay tile', \n",
    "                'mb': 'mod bit',  \n",
    "                'm':'metal',\n",
    "                'p': 'pvc/tpo', \n",
    "                'e': 'epdm', \n",
    "                'ra': 'rolled asphalt',  \n",
    "                'c': 'roof coating', \n",
    "                'b': 'ballasted',  \n",
    "                'bur': 'built-up'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = df.merge(label_df, left_on = 'file_name', right_on = 'VA_ID')\n",
    "\n",
    "# Rename the column for material for sanity's sake\n",
    "full_data.rename(columns = {'Material\\na = asphalt shingle   t = clay tile\\nmb = mod bit           m = metal\\np = pvc/tpo               e = epdm\\nra = rolled asphalt    c = roof coating \\nb = ballasted            bur = built-up':\n",
    "                           'material'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training CSV for Something other than Solaris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image urls and material labels from the full data set and rename them how Solaris wants\n",
    "solaris_train_df = full_data[['secure_url', 'material']].rename(columns = {'secure_url': 'image', 'material':'label'})\n",
    "\n",
    "# Remove all instances where a core material is present alongside other\n",
    "solaris_train_df = solaris_train_df[~solaris_train_df['label'].str.contains('-[mat]', regex = True)]\n",
    "solaris_train_df = solaris_train_df[~solaris_train_df['label'].str.contains('[mat]-', regex = True)]\n",
    "solaris_train_df = solaris_train_df[~solaris_train_df['label'].str.match('u')]\n",
    "\n",
    "# Map labels to meaningful names, with all materials outside of core 3 going into \"other\"\n",
    "solaris_train_df['label'][solaris_train_df.label == 'm'] = 'metal'\n",
    "solaris_train_df['label'][solaris_train_df.label == 'a'] = 'asphalt_shingle'\n",
    "solaris_train_df['label'][solaris_train_df.label == 't'] = 'clay_tile'\n",
    "mask = solaris_train_df.label.str.contains('metal|asphalt_shingle|clay_tile', regex = True)\n",
    "solaris_train_df['label'][~mask] = 'other'\n",
    "\n",
    "solaris_train_df.to_csv('data/material_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to get a prediction out of Solaris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solaris as sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/path/to/test_df.csv' does not exist: b'/path/to/test_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8ff2317584d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nets/configs/xdxd_spacenet4.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minferer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minference_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_infer_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minferer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/solaris/nets/infer.py\u001b[0m in \u001b[0;36mget_infer_df\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0minfer_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inference_data_csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minfer_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/solaris/utils/core.py\u001b[0m in \u001b[0;36mget_data_paths\u001b[0;34m(path, infer)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# no labels in those files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/solaris/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/path/to/test_df.csv' does not exist: b'/path/to/test_df.csv'"
     ]
    }
   ],
   "source": [
    "config = sol.utils.config.parse('nets/configs/xdxd_spacenet4.yml')\n",
    "inferer = sol.nets.infer.Inferer(config)\n",
    "inference_data = sol.nets.infer.get_infer_df(config)\n",
    "inferer(inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Something totally different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/Tyler/Downloads/material_labeling_dturk.tsv', \n",
    "                 delimiter = '\\t').drop(columns=['img_url', 'bv_detection', 'footprint_data', 'Summary', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.tyler_tag == 'asphalt_shingle'].drop(columns='tyler_tag').set_index('property_id').to_csv('/USERS/Tyler/Downloads/asphalt_shingle.txt')\n",
    "df[df.tyler_tag == 'metal'].drop(columns='tyler_tag').set_index('property_id').to_csv('/USERS/Tyler/Downloads/metal_panel.txt')\n",
    "df[df.tyler_tag == 'clay'].drop(columns='tyler_tag').set_index('property_id').to_csv('/USERS/Tyler/Downloads/clay_tile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
